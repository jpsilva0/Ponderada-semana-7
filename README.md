## Pergunta 1
&emsp;&emsp; O argumento num_examples determina a quantidade de exemplos de tradução de frases entre as línguas determinadas (nesse caso, francês e inglês). Assim, a alteração do seu tamanho determina a quantidade de informação que o modelo terá para ser treinado, o que afetará diretamente a quantidade de palavras conhecidas pelo modelo, e a corretude das traduções. Um número menor de num_examples representa uma amostra de dados menor, e consequentemente o modelo terá uma base de vocabulário reduzida tanto para o idioma de entrada quanto de saída.  Já um número maior do argumento representa uma base de dados mais robusta, e por consequência o modelo terá um vocabulário mais amplo, sendo capaz de identificar palavras mais incomuns em ambos os idiomas. 

## Pergunta 2
&emsp;&emsp; Em idiomas como Chinês ou Japonês, a identificação de palavras em uma frase se torna mais ambígua, já que não tem um separador claro entre palavras como o espaço em outras línguas. Nesse caso, se torna mais eficiente utilizar a tokenização a nível de caractere, já que, mesmo que se perca a palavra, cada caractere nessas línguas normalmente carrega uma parte do significado do termo. 
